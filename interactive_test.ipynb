{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfory Interactive Test Notebook\n",
    "\n",
    "Welcome! This notebook allows you to test the `Transfory` library in an interactive way.\n",
    "\n",
    "### Instructions:\n",
    "1.  **Activate Environment**: Make sure your virtual environment is activated.\n",
    "2.  **Install Dependencies**: From your project root, run `pip install -r requirements.txt` to install dependencies. For development, you can use `pip install -e .` to install `Transfory` in editable mode.\n",
    "3.  **Run All Cells**: Run the entire notebook (`Kernel -> Restart & Run All`) to see the complete workflow, from data creation to transformation, reporting, and persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transfory components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# To run this script from the project root, we add the current directory to the path\n",
    "# This allows Python to find the 'transfory' package\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import all components from your Transfory library\n",
    "# Note: Corrected import paths based on your file structure\n",
    "from transfory.pipeline import Pipeline\n",
    "from transfory.imputation import MissingValueHandler\n",
    "from transfory.encoder import Encoder\n",
    "from transfory.featuregen import FeatureGenerator\n",
    "from transfory.scaler import Scaler\n",
    "from transfory.insight import InsightReporter\n",
    "\n",
    "print(\"✅ Transfory components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Data\n",
    "\n",
    "To make this notebook self-contained, we'll create a sample DataFrame. It includes missing values and mixed data types to test all our transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   age         6 non-null      float64\n",
      " 1   city        6 non-null      object \n",
      " 2   experience  7 non-null      int64  \n",
      " 3   salary      6 non-null      float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 352.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>London</td>\n",
       "      <td>7</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>5</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>20</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>London</td>\n",
       "      <td>10</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age      city  experience    salary\n",
       "0  25.0  New York           2   50000.0\n",
       "1  30.0    London           7   90000.0\n",
       "2   NaN     Paris           5   75000.0\n",
       "3  45.0     Tokyo          20  150000.0\n",
       "4  35.0    London          10  110000.0\n",
       "5  28.0  New York           4       NaN\n",
       "6  50.0       NaN          22  180000.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Creates a sample DataFrame with mixed data types and missing values.\"\"\"\n",
    "    data = {\n",
    "        'age': [25, 30, np.nan, 45, 35, 28, 50],\n",
    "        'city': ['New York', 'London', 'Paris', 'Tokyo', 'London', 'New York', np.nan],\n",
    "        'experience': [2, 7, 5, 20, 10, 4, 22],\n",
    "        'salary': [50000, 90000, 75000, 150000, 110000, np.nan, 180000]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "raw_df = create_sample_data()\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "raw_df.info()\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Transformation Pipeline\n",
    "\n",
    "Here, we create an `InsightReporter` to track the changes and define a `Pipeline` with all the transformation steps. You can comment out, reorder, or customize the steps as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoder.__init__() got an unexpected keyword argument 'handle_unseen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m reporter = InsightReporter()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Define the full pipeline\u001b[39;00m\n\u001b[32m      5\u001b[39m full_pipeline = Pipeline([\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Step 1: Handle missing values\u001b[39;00m\n\u001b[32m      7\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mimputer_numeric\u001b[39m\u001b[33m\"\u001b[39m, MissingValueHandler(strategy=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)), \u001b[38;5;66;03m# Fills NaN in 'age' and 'salary' with their mean\u001b[39;00m\n\u001b[32m      8\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mimputer_categorical\u001b[39m\u001b[33m\"\u001b[39m, MissingValueHandler(strategy=\u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m)), \u001b[38;5;66;03m# Fills NaN in 'city' with its mode\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Step 2: Convert categorical columns to numbers\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mencoder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43monehot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unseen\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m), \u001b[38;5;66;03m# Use handle_unseen='error' to raise an error for new categories\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Step 3: Generate new features from numeric columns\u001b[39;00m\n\u001b[32m     14\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mfeature_generator\u001b[39m\u001b[33m\"\u001b[39m, FeatureGenerator(degree=\u001b[32m2\u001b[39m, include_interactions=\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Step 4: Scale all numeric features\u001b[39;00m\n\u001b[32m     17\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m\"\u001b[39m, Scaler(method=\u001b[33m\"\u001b[39m\u001b[33mzscore\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;66;03m# Applies Z-score scaling to all numeric columns\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m ], logging_callback=reporter.get_callback()) \u001b[38;5;66;03m# Attach the reporter to the pipeline\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPipeline defined:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m full_pipeline\n",
      "\u001b[31mTypeError\u001b[39m: Encoder.__init__() got an unexpected keyword argument 'handle_unseen'"
     ]
    }
   ],
   "source": [
    "# Create an InsightReporter to capture all events\n",
    "reporter = InsightReporter()\n",
    "\n",
    "# Define the full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    # Step 1: Handle missing values\n",
    "    (\"imputer_numeric\", MissingValueHandler(strategy=\"mean\")), # Fills NaN in 'age' and 'salary' with their mean\n",
    "    (\"imputer_categorical\", MissingValueHandler(strategy=\"mode\")), # Fills NaN in 'city' with its mode\n",
    "    \n",
    "    # Step 2: Convert categorical columns to numbers\n",
    "    (\"encoder\", Encoder(method=\"onehot\", handle_unseen=\"error\")), # Use handle_unseen='error' to raise an error for new categories\n",
    "    \n",
    "    # Step 3: Generate new features from numeric columns\n",
    "    (\"feature_generator\", FeatureGenerator(degree=2, include_interactions=True)),\n",
    "    \n",
    "    # Step 4: Scale all numeric features\n",
    "    (\"scaler\", Scaler(method=\"zscore\")) # Applies Z-score scaling to all numeric columns\n",
    "    \n",
    "], logging_callback=reporter.get_callback()) # Attach the reporter to the pipeline\n",
    "\n",
    "print(\"Pipeline defined:\")\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the Pipeline\n",
    "\n",
    "This cell executes the `fit_transform` method on your data, applying all the defined steps sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the data and transform it\n",
    "transformed_df = full_pipeline.fit_transform(raw_df)\n",
    "\n",
    "print(\"Transformed DataFrame (first 5 rows):\")\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: View the Insight Report\n",
    "\n",
    "The `InsightReporter` provides a human-readable summary of every action the pipeline took. This is the core of Transfory's **explainability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary from the reporter\n",
    "print(reporter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also view the raw log data as a DataFrame for more detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter.summary(as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save and Load the Pipeline (Persistence)\n",
    "\n",
    "A key feature is the ability to save your trained pipeline. This allows you to apply the *exact same transformations* to new, unseen data later (e.g., in a production environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted pipeline to a file\n",
    "pipeline_filepath = \"trained_transfory_pipeline.joblib\"\n",
    "full_pipeline.save(pipeline_filepath)\n",
    "\n",
    "print(f\"✅ Pipeline saved to '{pipeline_filepath}'\")\n",
    "\n",
    "# Load the pipeline back from the file\n",
    "loaded_pipeline = Pipeline.load(pipeline_filepath)\n",
    "\n",
    "print(f\"✅ Pipeline loaded successfully!\")\n",
    "print(loaded_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Transform New Data with the Loaded Pipeline\n",
    "\n",
    "Now, let's simulate receiving new data and use our `loaded_pipeline` to transform it. The loaded pipeline already knows the means, modes, and scaling parameters from the original data, ensuring consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some new, unseen data\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [60, np.nan],\n",
    "    'city': ['Paris', 'Dubai'], # 'Dubai' is an unseen category\n",
    "    'experience': [35, 1],\n",
    "    'salary': [250000, 45000]\n",
    "})\n",
    "\n",
    "print(\"New, unseen data:\")\n",
    "print(new_data)\n",
    "\n",
    "# Use the loaded pipeline (with handle_unseen='error') to transform the new data.\n",
    "# We expect this to fail because 'Dubai' is an unseen category.\n",
    "try:\n",
    "    print(\"\\nAttempting to transform new data with handle_unseen='error'...\")\n",
    "    new_data_transformed = loaded_pipeline.transform(new_data)\n",
    "    print(\"\\nTransformed new data:\")\n",
    "    print(new_data_transformed)\n",
    "except ValueError as e:\n",
    "    print(f\"\\n✅ SUCCESS: The pipeline correctly raised a ValueError as expected.\")\n",
    "    print(f\"Error message: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Demonstrate `handle_unseen='ignore'`\n",
    "\n",
    "Now, let's create a new pipeline with the default `handle_unseen='ignore'` policy. This time, the pipeline should not raise an error. Instead, it will create columns for the categories it knows ('New York', 'London', etc.) and assign `0` to all of them for the row containing 'Dubai'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new pipeline with the default 'ignore' policy\n",
    "ignore_pipeline = Pipeline([\n",
    "    (\"imputer_numeric\", MissingValueHandler(strategy=\"mean\")),\n",
    "    (\"imputer_categorical\", MissingValueHandler(strategy=\"mode\")),\n",
    "    (\"encoder\", Encoder(method=\"onehot\", handle_unseen=\"ignore\")) # Default behavior\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the original raw data\n",
    "ignore_pipeline.fit(raw_df)\n",
    "\n",
    "print(\"--- Transforming new data with handle_unseen='ignore' ---\")\n",
    "# Transform the new data. This should not raise an error.\n",
    "new_data_ignored = ignore_pipeline.transform(new_data)\n",
    "\n",
    "print(\"Transformed new data (unseen 'Dubai' is ignored):\")\n",
    "new_data_ignored"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
